import argparse
from bs4 import BeautifulSoup
from bs4 import Tag
from collections import OrderedDict
import itertools
import json
import os
import re
import StringIO
#import nltk
import operator
import sys
sys.path.append('/srv/www/easypce/')
from easypce import settings
from django.core.management import setup_environ
setup_environ(settings)
from models import *

# By Candy Button, Fall 2012 Independent Work with Brian Kernighan

# Using the Natural Language Toolkit:
# Bird, Steven, Edward Loper and Ewan Klein (2009). Natural Language Processing with Python. O'Reilly Media Inc.



def v(text):
    if Parser.VERBOSE:
        print text;

def readfile(filename):
    contents = None;
    with open(filename, 'r') as f:
        contents = f.read()
    return contents

def soupfile(filename):
    html = readfile(filename)
    return BeautifulSoup(html)

def isdatafile(filename):
    # TODO
    return not isadvicefile(filename)

def isadvicefile(filename):
    soup = soupfile(filename)
    tag = soup.find(name="ul")
    return (tag is not None)

def coursenum_from_filename(filename):
    match = re.search("[0-9]+?.*?_", filename)
    coursenum = match.group(0)[0:-1]
    print coursenum
    return coursenum

def coursedept_from_filename(filename):
    split = filename.split("/")
    name = split[-1]
    if (name == re.search("^\w\w\w\w\w\w\w_.*", name)):
        return name[:4]
    else:
        return name[:3]

class Parser:

    SAVE_FILE = "state_of_parser.json"
    VERBOSE = True

    def __init__(self):
        self.data = {}
        self.worddict={}

    def nextfilename(self):
        pass

    def load(self):
        try:
            f = open(Parser.SAVE_FILE, 'r')
            if f == None:
                return False
            self.data = json.load(f);
            f.close()
            v("******** LOADED DATA *******\n")
            return True
        except IOError:
            print "Failed loading data; file %s not readable" % Parser.SAVE_FILE
            return False

    def save(self):
        f = open(Parser.SAVE_FILE, 'w')
        json.dump(self.data, f)
        f.close()

    # This function requires the natural language toolkit - you must download it and 
    # uncomment the import statement (import nltk) at the top of this file
    def parse_words(self, sentences):
        words = nltk.word_tokenize(sentences)
        tags = nltk.pos_tag(words)
        
        for tag in tags:
            if tag[1] == 'JJ':
                word = tag[0];
                if self.worddict.get(word) == None:
                    self.worddict[word] = 1;
                else:
                    self.worddict[word] += 1;

    def saveCourse(self, filename, isadvicefile):
        print filename
        soup = soupfile(filename)
        if isadvicefile:
            h1 = soup.html.body.div.h1.string.split()
            semester = h1[-2]
            year = h1[-1]
        else:
            ys = soup.find('option', selected="selected")
            date = ys.string.split()
            semester = date[0]
            year = date[1]
            span = soup.find('span', style="font-size: larger;").string.split()
            title = span[2]
            for x in range(3, len(span)):
        	title = title + " " + span[x]
        #Check if department has been seen before. If not, add it to database.
        try:
            d = Department.objects.get(dept=coursedept_from_filename(filename))
        except Department.DoesNotExist:
            d = Department(dept=coursedept_from_filename(filename))
            d.save()
    
        # Add course if not already in database
    	try:
            c = Course.objects.get(
                number=coursenum_from_filename(filename),
                dept=Department.objects.get(dept=coursedept_from_filename(filename)),
                semester=semester,
                year=year
                )
        except Course.DoesNotExist:
            c = Course(
                number=coursenum_from_filename(filename),
                dept=Department.objects.get(dept=coursedept_from_filename(filename)),
                semester=semester,
                year=year,
                regNum=5,
                prof=Professor.objects.get(netid='mhaake'),
                title=title
        )
            c.save()
        return c

    def parse_advice(self, filename):
        soup = soupfile(filename)
        c = self.saveCourse(filename, True)

        tag = soup.find(name="ul")
        if tag == None:
            print "Couldn't find advice list for ", coursenum
            return False

        for item in tag.children:
            if isinstance(item, Tag) and item.name == "li":
                # Save the data in the Parser object
                # if self.data.get(filename) == None:
                #    self.data[filename] = []
                # self.data[filename].append(item.string.strip()) 

                # Or parse individual words from the string
                # self.parse_words(item.string.strip()); 

                # Print the string if in verbose mode

                #advicelists.append(advicelist)
                # INSERT YOUR CODE HERE,
                # use item.string.strip() as a single student's advice
                try:
                    t = item.string.strip()
                    a = Advice(
                        instance=c,
                        text=t)
                    a.save()
                except Course.DoesNotExist:
                    print "Need to load regular file first: " + filename
        return True

    def parse_numbers(self, filename):
        #coursenum = coursenum_from_filename(filename);
        #table = soup.find(name="table")
        # TODO: fill out the rest of the BeautifulSoup parsing to get the data here
        # INSERT YOUR CODE HERE      
        c = self.saveCourse(filename, False)
        soup = soupfile(filename)

        # Add evluation for course
        for s in soup('td', width="50%"):
            #print s.string
            try:
	    	e = Evaluation()
            	p = s.findNextSiblings(limit=9)
            	e.questiontext = str(s.string)
            	e.num_responses = p[0].string
	    	e.rate_responses = p[1].string
	    	e.excellent = p[2].string
	    	e.veryGood = p[3].string
	    	e.good = p[4].string
	    	e.fair = p[5].string
	    	e.poor = p[6].string
	    	e.na = p[7].string
	    	e.mean = p[8].string.strip()
	    	e.instance = c
            	e.save()
	    except:
		print "skip"

    def parse_dir(self):
        # "." means the current directory

#        files = filter(os.path.isfile, os.listdir('../../../curling/database_Load_Test'))
    	path = '/home/ubuntu/curling/advice/'
        files = os.listdir(path)
        for i, file in enumerate(files):
            files[i] = path + file

        #v("Advice files:")
        #for file in itertools.ifilter(isadvicefile, files):
        #    v(file)
        #    self.parse_advice(file)
        v("Data files:")
        for file in itertools.ifilter(isdatafile, files):
            v(file)
            self.parse_numbers(file)
        #v(self.data)

    def print_words(self):
        list = sorted(self.worddict.iteritems(), key=operator.itemgetter(1))
        for tuple in list:
            print "%s: %d" % tuple

parser = argparse.ArgumentParser()
parser.add_argument("-v", "--verbose", help="print out lots of junk for debugging", action="store_true")
args = parser.parse_args()
Parser.VERBOSE = args.verbose

p = Parser();
try:
    # Loading and saving don't do anything unless you store stuff in the parser's data field, 
    # and the parsing function ignores the loaded data, so there's no use in saving/loading here.
    # p.load();
    p.parse_dir();
    # Only if you've saved words in the parser's worddict...
    # p.print_words();
    # p.save();
except Exception, e: 
    z = e
    print z
